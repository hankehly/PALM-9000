{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pvporcupine\n",
    "import pyttsx3\n",
    "import scipy.io.wavfile\n",
    "import sounddevice as sd\n",
    "import webrtcvad\n",
    "import whisper\n",
    "from pvrecorder import PvRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1015f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NHK訪問営業部2 Microphone\n",
      "Device 1: USB PnP Sound Device\n",
      "Device 2: MacBook Pro Microphone\n",
      "Device 3: Microsoft Teams Audio\n"
     ]
    }
   ],
   "source": [
    "for i, device in enumerate(PvRecorder.get_available_devices()):\n",
    "    print('Device %d: %s' % (i, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518fb3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large',\n",
       " 'large-v3-turbo',\n",
       " 'turbo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b77c44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alexa',\n",
       " 'americano',\n",
       " 'blueberry',\n",
       " 'bumblebee',\n",
       " 'computer',\n",
       " 'grapefruit',\n",
       " 'grasshopper',\n",
       " 'hey barista',\n",
       " 'hey google',\n",
       " 'hey siri',\n",
       " 'jarvis',\n",
       " 'ok google',\n",
       " 'pico clock',\n",
       " 'picovoice',\n",
       " 'porcupine',\n",
       " 'terminator'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvporcupine.KEYWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19633053",
   "metadata": {},
   "source": [
    "# Wake Word Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"computer\", \"bumblebee\"]\n",
    "\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=os.getenv(\"PORCUPINE_ACCESS_KEY\"),\n",
    "    # Won't work on macOS, only Raspberry Pi\n",
    "    # keyword_paths=[\"~/Downloads/Hey-Palm-Tree_en_raspberry-pi_v3_0_0/Hey-Palm-Tree_en_raspberry-pi_v3_0_0.ppn\"],\n",
    "    keywords=keywords,\n",
    ")\n",
    "\n",
    "recorder = PvRecorder(frame_length=porcupine.frame_length, device_index=1)\n",
    "recorder.start()\n",
    "\n",
    "print(\"Listening ... (press Ctrl+C to exit)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        pcm = recorder.read()\n",
    "        result = porcupine.process(pcm)\n",
    "        if result >= 0:\n",
    "            print(\"[%s] Detected %s\" % (str(datetime.datetime.now()), keywords[result]))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping ...\")\n",
    "finally:\n",
    "    recorder.delete()\n",
    "    porcupine.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee2ffe",
   "metadata": {},
   "source": [
    "# Voice Activity Detection (VAD) and Audio Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d2f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "FRAME_DURATION_MS = 30\n",
    "FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)  # samples per frame\n",
    "SILENCE_TIMEOUT = 2.0  # seconds of silence to trigger stop\n",
    "VAD_MODE = 2  # 0-3: more aggressive = more sensitive to voice\n",
    "\n",
    "\n",
    "def record_audio():\n",
    "    vad = webrtcvad.Vad(VAD_MODE)\n",
    "\n",
    "    recording = False\n",
    "    silence_start = None\n",
    "\n",
    "    stream = sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        channels=1,\n",
    "        dtype=\"int16\",\n",
    "        blocksize=FRAME_SIZE,\n",
    "        device=1,\n",
    "    )\n",
    "    stream.start()\n",
    "\n",
    "    audio_data = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            block, _ = stream.read(FRAME_SIZE)\n",
    "            samples = block[:, 0].tobytes()\n",
    "\n",
    "            is_speech = vad.is_speech(samples, SAMPLE_RATE)\n",
    "\n",
    "            if is_speech:\n",
    "                if not recording:\n",
    "                    print(\"🧠 Detected speech. Recording...\")\n",
    "                    recording = True\n",
    "                silence_start = None\n",
    "                audio_data.append(samples)\n",
    "            elif recording:\n",
    "                if silence_start is None:\n",
    "                    silence_start = time.time()\n",
    "                elif time.time() - silence_start > SILENCE_TIMEOUT:\n",
    "                    print(\"🤫 Silence detected. Stopping recording.\")\n",
    "                    break\n",
    "\n",
    "    finally:\n",
    "        stream.stop()\n",
    "\n",
    "    return b\"\".join(audio_data)\n",
    "\n",
    "\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_bytes) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio bytes using Whisper.\n",
    "    \"\"\"\n",
    "    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\") as tmpfile:\n",
    "        scipy.io.wavfile.write(tmpfile.name, SAMPLE_RATE, audio_array)\n",
    "        result = whisper_model.transcribe(tmpfile.name)\n",
    "        return result[\"text\"]\n",
    "\n",
    "\n",
    "def speak_text(text):\n",
    "    tts = pyttsx3.init()\n",
    "    tts.say(text)\n",
    "    tts.runAndWait()\n",
    "    tts.stop()\n",
    "\n",
    "\n",
    "# print(\"🎙️ PALM‑9000 is listening for your message...\")\n",
    "\n",
    "# # Get voice input\n",
    "# audio_bytes = record_audio()\n",
    "\n",
    "# # Transcribe with Whisper\n",
    "# text = transcribe_audio(audio_bytes)\n",
    "\n",
    "# # Print and speak the result\n",
    "# speak_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97010268",
   "metadata": {},
   "source": [
    "# Putting it All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aceb4aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening ... (press Ctrl+C to exit)\n",
      "[2025-07-01 18:09:32.824803] Detected computer\n",
      "Wake word detected.\n",
      "🧠 Detected speech. Recording...\n",
      "🤫 Silence detected. Stopping recording.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hankehly/Projects/PALM-9000/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User said:  A, B, C, D, E, F, G.\n",
      "Stopping ...\n"
     ]
    }
   ],
   "source": [
    "keywords = [\"computer\", \"bumblebee\"]\n",
    "\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=os.getenv(\"PORCUPINE_ACCESS_KEY\"),\n",
    "    # Won't work on macOS, only Raspberry Pi\n",
    "    # keyword_paths=[\"~/Downloads/Hey-Palm-Tree_en_raspberry-pi_v3_0_0/Hey-Palm-Tree_en_raspberry-pi_v3_0_0.ppn\"],\n",
    "    keywords=keywords,\n",
    ")\n",
    "\n",
    "\n",
    "def on_wake_word():\n",
    "    print(\"Wake word detected.\")\n",
    "\n",
    "    audio_bytes = record_audio()\n",
    "\n",
    "    text = transcribe_audio(audio_bytes)\n",
    "\n",
    "    print(\"User said:\", text)\n",
    "\n",
    "    # Get LLM response\n",
    "    # response = palm_9000_llm.invoke([HumanMessage(content=text)])\n",
    "\n",
    "    # Speak\n",
    "    speak_text(text)\n",
    "\n",
    "\n",
    "recorder = PvRecorder(frame_length=porcupine.frame_length, device_index=1)\n",
    "recorder.start()\n",
    "\n",
    "print(\"Listening ... (press Ctrl+C to exit)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        pcm = recorder.read()\n",
    "        result = porcupine.process(pcm)\n",
    "        if result >= 0:\n",
    "            print(\"[%s] Detected %s\" % (str(datetime.datetime.now()), keywords[result]))\n",
    "            on_wake_word()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping ...\")\n",
    "finally:\n",
    "    recorder.delete()\n",
    "    porcupine.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palm-9000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
