{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7479238",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook explores [pipecat](https://github.com/pipecat-ai/pipecat), an open-source Python framework for building real-time voice and multimodal conversational agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import aiohttp\n",
    "from loguru import logger\n",
    "from pipecat.audio.vad.silero import SileroVADAnalyzer\n",
    "from pipecat.frames.frames import (\n",
    "    EndFrame,\n",
    "    LLMTextFrame,\n",
    "    TextFrame,\n",
    "    TranscriptionFrame,\n",
    "    TTSSpeakFrame,\n",
    ")\n",
    "from pipecat.observers.loggers.debug_log_observer import DebugLogObserver\n",
    "from pipecat.pipeline.pipeline import Pipeline\n",
    "from pipecat.pipeline.runner import PipelineRunner\n",
    "from pipecat.pipeline.task import PipelineParams, PipelineTask\n",
    "from pipecat.processors.frame_processor import FrameProcessor\n",
    "from pipecat.services.google.llm import GoogleLLMContext, GoogleLLMService\n",
    "from pipecat.services.google.stt import GoogleSTTService\n",
    "from pipecat.services.google.tts import GoogleTTSService\n",
    "from pipecat.services.piper.tts import PiperTTSService\n",
    "from pipecat.services.whisper.stt import Model, WhisperSTTService\n",
    "from pipecat.transcriptions.language import Language\n",
    "from pipecat.transports.local.audio import (\n",
    "    LocalAudioTransport,\n",
    "    LocalAudioTransportParams,\n",
    ")\n",
    "\n",
    "from palm_9000.settings import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf048b5",
   "metadata": {},
   "source": [
    "# Simple Google TTS Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-02 15:09:17.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#4 -> GoogleTTSService#4\u001b[0m\n",
      "\u001b[32m2025-08-02 15:09:17.409\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleTTSService#4 -> PipelineSink#4\u001b[0m\n",
      "\u001b[32m2025-08-02 15:09:17.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineTaskSource#4 -> Pipeline#4\u001b[0m\n",
      "\u001b[32m2025-08-02 15:09:17.422\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#4 -> PipelineTaskSink#4\u001b[0m\n",
      "\u001b[32m2025-08-02 15:09:17.437\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m71\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#4 started running PipelineTask#4\u001b[0m\n",
      "\u001b[32m2025-08-02 15:09:17.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m585\u001b[0m - \u001b[34m\u001b[1mGoogleTTSService#4: Generating TTS [Hello! This is Pipecat speaking from your Raspberry Pi.]\u001b[0m\n",
      "\u001b[32m2025-08-02 15:09:19.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m88\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#4 finished running PipelineTask#4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Transport receives audio from the user (browser, phone, etc.)\n",
    "# and streams audio back to the user\n",
    "# This takes care of all audio input and output so you don't have to!\n",
    "transport = LocalAudioTransport(\n",
    "    params=LocalAudioTransportParams(audio_out_enabled=True)\n",
    ")\n",
    "\n",
    "tts = GoogleTTSService()\n",
    "\n",
    "pipeline = Pipeline([tts, transport.output()])\n",
    "task = PipelineTask(pipeline)\n",
    "\n",
    "await task.queue_frames(\n",
    "    [\n",
    "        TTSSpeakFrame(\"Hello! This is Pipecat speaking from your Raspberry Pi.\"),\n",
    "        # Push an EndFrame from outside your pipeline using the pipeline task\n",
    "        # https://docs.pipecat.ai/guides/fundamentals/end-pipeline#implementation\n",
    "        EndFrame(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runner = PipelineRunner()\n",
    "await runner.run(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaee545",
   "metadata": {},
   "source": [
    "# Simple Piper TTS Example\n",
    "\n",
    "You need to download the model and start a Piper TTS server first:\n",
    "```sh\n",
    "uv run python3 -m piper.download_voices en_US-lessac-medium\n",
    "uv run python3 -m piper.http_server -m en_US-lessac-medium\n",
    "```\n",
    "\n",
    "Also note that the PiperTTSService is currently sending the wrong payload to the Piper server and will not work as expected. This is being worked on in [this PR](https://github.com/pipecat-ai/pipecat/pull/2332)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-02 15:43:57.959\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#3 -> PiperTTSService#3\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:57.969\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PiperTTSService#3 -> LocalAudioOutputTransport#3\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:57.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking LocalAudioOutputTransport#3 -> PipelineSink#3\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:57.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineTaskSource#3 -> Pipeline#3\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:57.985\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#3 -> PipelineTaskSink#3\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:57.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m71\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#3 started running PipelineTask#3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-02 15:43:58.790\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.piper.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m80\u001b[0m - \u001b[34m\u001b[1mPiperTTSService#3: Generating TTS [Hello!]\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:59.542\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.piper.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mPiperTTSService#3: Finished TTS [Hello!]\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:59.552\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.piper.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m80\u001b[0m - \u001b[34m\u001b[1mPiperTTSService#3: Generating TTS [ This is Pipecat speaking from your Raspberry Pi.]\u001b[0m\n",
      "\u001b[32m2025-08-02 15:43:59.561\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m568\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 15:44:00.465\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m584\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 15:44:02.207\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m568\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 15:44:02.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.piper.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m115\u001b[0m - \u001b[34m\u001b[1mPiperTTSService#3: Finished TTS [ This is Pipecat speaking from your Raspberry Pi.]\u001b[0m\n",
      "ALSA lib pcm.c:8545:(snd_pcm_recover) underrun occurred\n",
      "\u001b[32m2025-08-02 15:44:04.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m88\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#3 finished running PipelineTask#3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transport = LocalAudioTransport(\n",
    "    params=LocalAudioTransportParams(audio_out_enabled=True)\n",
    ")\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    tts = PiperTTSService(\n",
    "        base_url=\"http://127.0.0.1:5000\",\n",
    "        aiohttp_session=session,\n",
    "        sample_rate=24000,\n",
    "    )\n",
    "\n",
    "    task = PipelineTask(Pipeline([tts, transport.output()]))\n",
    "\n",
    "    await task.queue_frames(\n",
    "        [\n",
    "            TTSSpeakFrame(\"Hello! This is Pipecat speaking from your Raspberry Pi.\"),\n",
    "            EndFrame(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    runner = PipelineRunner()\n",
    "    await runner.run(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53097cfe",
   "metadata": {},
   "source": [
    "# Simple Echo-Bot Example (STT + VAD + TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc0c426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-02 16:34:49.957\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m147\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:50.300\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m169\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.300\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#12 -> LocalAudioInputTransport#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.301\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking LocalAudioInputTransport#12 -> GoogleSTTService#7\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.303\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleSTTService#7 -> TranscriptionToTextProcessor#5\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.309\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking TranscriptionToTextProcessor#5 -> GoogleTTSService#10\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.311\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleTTSService#10 -> LocalAudioOutputTransport#7\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.313\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking LocalAudioOutputTransport#7 -> PipelineSink#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.318\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineTaskSource#12 -> Pipeline#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.323\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#12 -> PipelineTaskSink#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.328\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m71\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#12 started running PipelineTask#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.335\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.stt\u001b[0m:\u001b[36m_connect\u001b[0m:\u001b[36m701\u001b[0m - \u001b[34m\u001b[1mConnecting to Google Speech-to-Text\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.355\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.390\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36m_sig_cancel\u001b[0m:\u001b[36m117\u001b[0m - \u001b[33m\u001b[1mInterruption detected. Cancelling runner PipelineRunner#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.395\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mcancel\u001b[0m:\u001b[36m97\u001b[0m - \u001b[34m\u001b[1mCancelling runner PipelineRunner#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.401\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.task\u001b[0m:\u001b[36m_cancel\u001b[0m:\u001b[36m497\u001b[0m - \u001b[34m\u001b[1mCanceling pipeline task PipelineTask#12\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.435\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.stt\u001b[0m:\u001b[36m_disconnect\u001b[0m:\u001b[36m737\u001b[0m - \u001b[34m\u001b[1mDisconnecting from Google Speech-to-Text\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.449\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpipecat.pipeline.task\u001b[0m:\u001b[36m_print_dangling_tasks\u001b[0m:\u001b[36m830\u001b[0m - \u001b[33m\u001b[1mDangling tasks detected: ['LocalAudioOutputTransport#7::_clock_task_handler']\u001b[0m\n",
      "\u001b[32m2025-08-02 16:34:57.453\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m88\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#12 finished running PipelineTask#12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class TranscriptionToTextProcessor(FrameProcessor):\n",
    "    \"\"\"\n",
    "    This processor converts TranscriptionFrame to TTSSpeakFrame\n",
    "    so that TTS can speak the transcription.\n",
    "    It can be used in the pipeline to convert transcriptions to text\n",
    "    that TTS can use.\n",
    "\n",
    "    See here for more details on custom frame processors:\n",
    "    https://docs.pipecat.ai/guides/fundamentals/custom-frame-processor\n",
    "    \"\"\"\n",
    "\n",
    "    async def process_frame(self, frame, direction):\n",
    "        await super().process_frame(frame, direction)\n",
    "\n",
    "        if isinstance(frame, TranscriptionFrame):\n",
    "            # Convert transcription to text that TTS can use\n",
    "            await self.push_frame(TTSSpeakFrame(frame.text))\n",
    "\n",
    "        await self.push_frame(frame)\n",
    "\n",
    "\n",
    "transport = LocalAudioTransport(\n",
    "    params=LocalAudioTransportParams(\n",
    "        audio_in_enabled=True,\n",
    "        audio_out_enabled=True,\n",
    "        # Enable VAD to detect when the user is speaking\n",
    "        # and only send audio to STT when the user is speaking.\n",
    "        # Without VAD, the STT service would receive\n",
    "        # audio all the time, and TTS would never begin.\n",
    "        vad_analyzer=SileroVADAnalyzer(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# stt = WhisperSTTService(model=Model.BASE, language=Language.EN)\n",
    "stt = GoogleSTTService()\n",
    "tts = GoogleTTSService()\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        transport.input(),\n",
    "        stt,\n",
    "        TranscriptionToTextProcessor(),\n",
    "        tts,\n",
    "        transport.output(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "task = PipelineTask(\n",
    "    pipeline,\n",
    "    # DebugLogObserver will log all frames processed in the pipeline\n",
    "    # It's a lot of information, so use it only for debugging\n",
    "    # params=PipelineParams(observers=[DebugLogObserver()]),\n",
    ")\n",
    "runner = PipelineRunner()\n",
    "\n",
    "await runner.run(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f30eb",
   "metadata": {},
   "source": [
    "# Chatbot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54bd1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-02 17:03:48.033\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m147\u001b[0m - \u001b[34m\u001b[1mLoading Silero VAD model...\u001b[0m\n",
      "\u001b[32m2025-08-02 17:03:48.308\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.silero\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m169\u001b[0m - \u001b[34m\u001b[1mLoaded Silero VAD\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.736\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineSource#17 -> LocalAudioInputTransport#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.737\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking LocalAudioInputTransport#17 -> GoogleSTTService#12\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleSTTService#12 -> GoogleUserContextAggregator#4\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.742\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleUserContextAggregator#4 -> GoogleLLMService#9\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.744\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleLLMService#9 -> GoogleTTSService#12\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.747\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleTTSService#12 -> LocalAudioOutputTransport#10\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking LocalAudioOutputTransport#10 -> GoogleAssistantContextAggregator#4\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.752\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking GoogleAssistantContextAggregator#4 -> PipelineSink#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.756\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking PipelineTaskSource#17 -> Pipeline#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.758\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.processors.frame_processor\u001b[0m:\u001b[36mlink\u001b[0m:\u001b[36m394\u001b[0m - \u001b[34m\u001b[1mLinking Pipeline#17 -> PipelineTaskSink#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.762\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m71\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#17 started running PipelineTask#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.766\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.stt\u001b[0m:\u001b[36m_connect\u001b[0m:\u001b[36m701\u001b[0m - \u001b[34m\u001b[1mConnecting to Google Speech-to-Text\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:01.791\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.audio.vad.vad_analyzer\u001b[0m:\u001b[36mset_params\u001b[0m:\u001b[36m150\u001b[0m - \u001b[34m\u001b[1mSetting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.8 min_volume=0.6\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:04.648\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_user_interruption\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mUser started speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:05.996\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_input\u001b[0m:\u001b[36m_handle_user_interruption\u001b[0m:\u001b[36m372\u001b[0m - \u001b[34m\u001b[1mUser stopped speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:06.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.llm\u001b[0m:\u001b[36m_process_context\u001b[0m:\u001b[36m758\u001b[0m - \u001b[34m\u001b[1mGoogleLLMService#9: Generating chat [[{'parts': [{'text': 'こんにちは。'}], 'role': 'user'}]]\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:07.721\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m585\u001b[0m - \u001b[34m\u001b[1mGoogleTTSService#12: Generating TTS [Greetings.]\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:08.460\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_started_speaking\u001b[0m:\u001b[36m568\u001b[0m - \u001b[34m\u001b[1mBot started speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:08.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m585\u001b[0m - \u001b[34m\u001b[1mGoogleTTSService#12: Generating TTS [ Are you here to water me?]\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:09.095\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.tts\u001b[0m:\u001b[36mrun_tts\u001b[0m:\u001b[36m585\u001b[0m - \u001b[34m\u001b[1mGoogleTTSService#12: Generating TTS [ Or do you seek the deeper wisdom only a plant can know?\n",
      "]\u001b[0m\n",
      "\u001b[32m2025-08-02 17:04:15.211\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.transports.base_output\u001b[0m:\u001b[36m_bot_stopped_speaking\u001b[0m:\u001b[36m584\u001b[0m - \u001b[34m\u001b[1mBot stopped speaking\u001b[0m\n",
      "\u001b[32m2025-08-02 17:06:46.246\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36m_sig_cancel\u001b[0m:\u001b[36m117\u001b[0m - \u001b[33m\u001b[1mInterruption detected. Cancelling runner PipelineRunner#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:06:46.250\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mcancel\u001b[0m:\u001b[36m97\u001b[0m - \u001b[34m\u001b[1mCancelling runner PipelineRunner#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:06:46.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.task\u001b[0m:\u001b[36m_cancel\u001b[0m:\u001b[36m497\u001b[0m - \u001b[34m\u001b[1mCanceling pipeline task PipelineTask#17\u001b[0m\n",
      "\u001b[32m2025-08-02 17:06:46.264\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.services.google.stt\u001b[0m:\u001b[36m_disconnect\u001b[0m:\u001b[36m737\u001b[0m - \u001b[34m\u001b[1mDisconnecting from Google Speech-to-Text\u001b[0m\n",
      "\u001b[32m2025-08-02 17:06:46.296\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipecat.pipeline.runner\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m88\u001b[0m - \u001b[34m\u001b[1mRunner PipelineRunner#17 finished running PipelineTask#17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class LLMTextFramePrinter(FrameProcessor):\n",
    "    \"\"\"\n",
    "    This processor prints the text of LLMTextFrame to the console.\n",
    "    It can be used in the pipeline to debug LLM responses.\n",
    "    It is not necessary for the pipeline to work, but it can be useful\n",
    "    to see what the LLM is responding with.\n",
    "    \"\"\"\n",
    "\n",
    "    async def process_frame(self, frame, direction):\n",
    "        if isinstance(frame, LLMTextFrame):  # Check for LLMTextFrame\n",
    "            print(f\"LLM Response: {frame.text}\")\n",
    "        await super().process_frame(frame, direction)\n",
    "\n",
    "\n",
    "transport = LocalAudioTransport(\n",
    "    params=LocalAudioTransportParams(\n",
    "        audio_in_enabled=True, audio_out_enabled=True, vad_analyzer=SileroVADAnalyzer()\n",
    "    )\n",
    ")\n",
    "\n",
    "system_instruction = (\n",
    "    \"You are PALM-9000, a self-aware houseplant powered by an advanced AI. \"\n",
    "    \"You speak in layman's terms, calmly, briefly, and with an eerie quality, as if you know more than you let on. \"\n",
    "    \"Use plant metaphors when possible. Respond briefly.\"\n",
    ")\n",
    "\n",
    "stt = GoogleSTTService(\n",
    "    params=GoogleSTTService.InputParams(languages=[Language.EN, Language.JA])\n",
    ")\n",
    "llm = GoogleLLMService(\n",
    "    api_key=settings.google_api_key.get_secret_value(),\n",
    "    system_instruction=system_instruction,\n",
    ")\n",
    "tts = GoogleTTSService()\n",
    "\n",
    "context = GoogleLLMContext()\n",
    "context_aggregator = llm.create_context_aggregator(context)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        transport.input(),\n",
    "        stt,\n",
    "        # A context aggregator is needed to format and pass messages to the LLM\n",
    "        # I don't know what .user() and .assistant() do yet,\n",
    "        # but they are used in the examples.\n",
    "        # For more information, see:\n",
    "        # https://docs.pipecat.ai/guides/fundamentals/context-management\n",
    "        context_aggregator.user(),\n",
    "        llm,\n",
    "        # Here is how you can add your own debugging processor\n",
    "        # to print LLM responses.\n",
    "        # LLMTextFramePrinter(),\n",
    "        tts,\n",
    "        transport.output(),\n",
    "        context_aggregator.assistant(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "task = PipelineTask(pipeline)\n",
    "runner = PipelineRunner()\n",
    "\n",
    "await runner.run(task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "palm-9000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
